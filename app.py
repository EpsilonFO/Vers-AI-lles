import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch
import os

# --- Configuration de la page ---
st.set_page_config(
    page_title="ğŸ‘‘ Versailles Assistant",
    page_icon="ğŸ°",
    layout="centered"
)

st.title("ğŸ‘‘ Assistant du ChÃ¢teau de Versailles")
st.caption("Posez vos questions sur les billets, horaires, transports, hÃ©bergements, ou mÃ©tÃ©o Ã  Versailles.")

# --- Chargement du modÃ¨le Mistral local ---
@st.cache_resource
def load_mistral():
    # ğŸ”¹ Utilisation du chemin local vers le modÃ¨le
    model_path = "Mistral-7B-Instruct-v0.1"

    # VÃ©rifie que le dossier existe
    '''if not os.path.exists(model_path):
        st.error(f"âŒ Le dossier du modÃ¨le n'existe pas : {model_path}")
        st.stop()'''

    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        device_map="auto"
    )

    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=512,
        temperature=0.3,
        do_sample=True,
        top_p=0.9
    )
    return pipe

with st.spinner("Chargement du modÃ¨le local Mistral... â³"):
    pipe = load_mistral()

st.success("ModÃ¨le Mistral chargÃ© avec succÃ¨s âœ…")

# --- Gestion de la session ---
if "history" not in st.session_state:
    st.session_state.history = []

# --- EntrÃ©e utilisateur ---
user_input = st.chat_input("Ã‰crivez votre question ici...")

def generate_response(user_message: str) -> str:
    """
    GÃ©nÃ¨re la rÃ©ponse Ã  partir du modÃ¨le local.
    """
    prompt = f"""Tu es un assistant de voyage expert du ChÃ¢teau de Versailles.
RÃ©ponds de maniÃ¨re claire, polie et utile Ã  la question suivante :

Utilisateur : {user_message}
RÃ©ponse :"""

    output = pipe(prompt)[0]["generated_text"]
    response = output.split("RÃ©ponse :")[-1].strip()
    return response

# --- Interaction utilisateur ---
if user_input:
    with st.spinner("L'assistant rÃ©flÃ©chit... ğŸ¤”"):
        response = generate_response(user_input)

    # Sauvegarde dans l'historique
    st.session_state.history.append(("ğŸ‘©â€ğŸ’¬ Vous", user_input))
    st.session_state.history.append(("ğŸ¤– Assistant", response))

# --- Affichage du chat ---
for speaker, msg in st.session_state.history:
    if "Vous" in speaker:
        st.markdown(f"**{speaker}:** {msg}")
    else:
        st.markdown(f"> ğŸ’¬ **{speaker}:** {msg}")

# --- Bouton reset ---
if st.button("ğŸ§¹ RÃ©initialiser la conversation"):
    st.session_state.history = []
    st.success("Conversation rÃ©initialisÃ©e âœ…")
